\capitulo{7}{Conclusiones y Líneas de trabajo futuras}

\section{Conclusión}
Respecto a los requisitos iniciales del proyecto, pienso que se han cumplido en su mayor medida. Dado a que este proyecto ha sido un proyecto de investigación, hay determinados objetivos que han podido ir cambiando a lo largo del proyecto. Por ello, los objetivos principales de realizar una investigación extensa y documentada y, finalmente, realizar una aplicación base de ejemplo, se han cumplido. 

Cabe destacar que aunque evidentemente todo el proceso de minería de datos y realización de experimentos fue arduo, los primeros pasos de la investigación les considero como los más complejos. Esto es debido a que se quería construir una buena base bien documentada de la investigación y así, poder dar los pasos de manera más firme. Es por eso que las tareas de resumen del estado del arte, identificación de metodologías y adquisición de un conjunto de audios con el que poder trabajar fueron muy costosos por diversos motivos (dificultad de encontrar metodologías, sin respuesta de dueños de las bases de datos...).

En lineas generales, en este trabajo se ha desarrollado una serie de experimentos sobre el tema relacionado de análisis de audios para la detección del Parkinson bastante extenso. Hemos obtenido muchos conjuntos de características de los audios (108 diferentes, extraídos de diferentes formas) con los que se han hecho muchos experimentos. Cada paso que hemos ido dando en el proyecto, ha sido con el objetivo de ir mejorando los resultados obtenidos por nosotros. 

Cabe destacar que los resultados por si solos no son malos, incluso están en la medida de los resultados de algunos artículos (tabla de resultados del estado del arte recogida en \cite{MxLtNovel}). Sin embargo, al estar siguiendo en este proyecto el proceso de \cite{Orz2016}, con el mismo conjunto de audios y las mismas herramientas, cualquier resultado que estuviera lejos del 0,98 o 0,99 AUC nos ha parecido 'bajo'. Destacamos que la base de datos es pequeña ya que, aunque haya 2000 audios, como ya se ha comentado no se pueden entrenar modelos con todos los audios a la vez, hay que dividirlos por tipos, lo que hace que tengamos conjuntos de datos de 50 a 300 instancias.

Si nos olvidamos de la diferencia de resultados con ese artículo concreto, ha sido una labor de experimentación en la labor de Minería de Datos muy satisfactoria. Se han comprendido todas las etapas de la misma, desde la recopilación de datos y la extracción de características, hasta las labores finales de interpretar los resultados. La gran cantidad de diversos experimentos y técnicas utilizadas han servido para aprender en profundidad cómo funcionan los diferentes algoritmos y herramientas de este campo.

En resumen, tanto con la labor de investigación y su documentación, como con la labor de realización de experimentos, como con la realización aplicación final estoy satisfecho.



\section{Líneas futuras}
Se sugieren varios caminos diferentes de investigación, así como varios detalles a mejorar y desarrollar del proyecto:
\begin{itemize}
\item Primeramente, se sugiere que, en vez de realizar una tarea de clasificación entre PD y HC, se realicen \textbf{experimentos de regresión sobre la escala UPDRS}. Es decir, en vez de únicamente decir si una persona tiene Parkinson o no, realizar una regresión para ver que nivel de Parkinson tiene en la escala UPDRS. Abordar el problema de esta manera, se empezó a ver en \cite{MxLtAccurate}. Para esta tarea de regresión se podrá experimentar con todos los conjuntos los conjuntos de características extraídos, incluidos los \english{embeddings}. En principio, iba a ser también uno de los objetivos del proyecto. Sin embargo, al no llegar al rendimiento esperado en clasificación, se optó por realizar más experimentos de clasificación en vez de comenzar con regresión.
\item Con objetivo de mejorar los resultados de los experimentos, se podrán probar diferentes elementos que mejoren su resultado. Uno de ellos es \textbf{probar otros selectores de atributos}. En este proyecto hemos probado PCA, \english{Select K Best} y \english{Variance Treshold}. PCA es un reductor de dimensionalidad. Los otros dos son algoritmos de selección de atributos que se basan en cada atributo individual para su elección. Por ello, como mejora se podrían elegir nuevos selectores de atributos, basados en modelos de aprendizaje (i.e. \english{SelectFromModel} de \textit{Scikit-Learn}) o basados en grupos de atributos (i.e. \english{Recursive feature elimination} de \textit{Scikit-Learn}).
\item Otra perspectiva diferente puede ser \textbf{tratar de manera diferente los \english{embeddings}}. Como hemos comentado, VGGish saca un vector de características para cada fragmento de 0.975s de cada audio. Nuestra solución ha sido hacer la media y desviación para obtener un único vector de características de todos los fragmentos de cada audio. Sin embargo se podrán probar otras perspectivas.
	\begin{itemize}
	\item La primera que se sugiere es, además de sacar la media y desviación, obtener también la \textbf{curtosis y el coeficiente de asimetría} (ver sección \ref{subsec:medidasdistribucion}). Esto ayudará a no desechar tanta información, y puede ser que ayude a mejorar los resultados.
	\item Otra perspectiva que se sugiere es la siguiente: clasificar cada vector devuelto por VGGish por separado, como si fuera un audio diferente, y devolver para ese audio la predicción mayoritaria de las predicciones de sus segmentos. Es decir, para un audio, clasificar cada 0.975s que analiza VGGish por separado de manera independiente y devolver la predicción mayoritaria.
	\end{itemize}
\item Por otro lado, de VGGish únicamente hemos usado la red de extracción de características. También podemos probar a \textbf{modificar la red de clasificación} del proyecto VGGish para que saque 2 salidas, en vez de las 600 que ahora tiene, y probarla sobre nuestro problema.
\item Una mejora que se puede añadir a los experimentos actuales es la siguiente. En el experimento que imita al realizado en \cite{Orz2016}, se utiliza un SVM con kernel gaussiano. La búsqueda de parámetros definida en dicho artículo, dice que buscan el parámetro $C$ y $\lambda$ en los rangos de [1, 10000]. Sin embargo, en los experimentos de la tercera fase, hemos añadido el valor  \textit{auto} para $\lambda$ , que en \english{Scikit-Learn} se corresponde con 1/número\_atribs. Por ello, también se llega a la conclusión, y se sugiere, que en experimentos futuros se realice la \textbf{búsqueda del parámetro $\lambda$} en el rango [1/1000, 1] $\rightarrow$ (1/1000, ..., 1/100, ..., 1/10, ...,1), en vez en el rango [1, 10000].
\item Para terminar, se sugiere la mejora de la aplicación. A parte de mejoras estéticas, se sugiere el uso de \textbf{diferentes clasificadores en función de los detalles} del paciente de entrada y del audio (vocal, palabra o frase). Actualmente utilizamos un clasificador único. La mejora sería derivar la clasificación a un clasificador u a otro en función del sexo, edad y tipo de audio introducido.
\end{itemize}
