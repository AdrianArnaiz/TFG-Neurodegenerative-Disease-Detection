{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from sklearn.utils import Bunch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>HY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>UPDRS</th>\n",
       "      <th>UPDRS_SPEECH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0001</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0002</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0003</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0005</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0006</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0007</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0008</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0009</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0010</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0011</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE  HY  SEX  UPDRS  UPDRS_SPEECH\n",
       "AVPEPUDEA0001   64   2    0     28             1\n",
       "AVPEPUDEA0002   72   1    1     19             0\n",
       "AVPEPUDEA0003   75   3    1     52             2\n",
       "AVPEPUDEA0005   65   2    0     32             1\n",
       "AVPEPUDEA0006   66   2    1     28             1\n",
       "AVPEPUDEA0007   55   2    1     30             1\n",
       "AVPEPUDEA0008   60   2    1     29             1\n",
       "AVPEPUDEA0009   57   3    1     41             1\n",
       "AVPEPUDEA0010   51   3    1     38             2\n",
       "AVPEPUDEA0011   55   3    1     43             2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos el diccionario con la estructura indicada\n",
    "filepath = '../PC-GITA/PCGITA_metadata.csv'\n",
    "dic_audios_inf = dict()\n",
    "with open(filepath) as fp:\n",
    "    cnt = 0\n",
    "    for line in fp:\n",
    "        line = line.split(';')[:8]\n",
    "        if not line[0].startswith('AVP'):\n",
    "            line[0]=line[0][3:]\n",
    "        dic_audios_inf[line[0]]=dict()\n",
    "        dic_audios_inf[line[0]]['UPDRS'] = 0 if line[1]=='' else int(line[1])\n",
    "        dic_audios_inf[line[0]]['UPDRS_SPEECH'] = 0 if line[2]=='' else int(line[2])\n",
    "        dic_audios_inf[line[0]]['HY'] = 0 if line[3]=='' else int(line[3][0])\n",
    "        dic_audios_inf[line[0]]['SEX'] = 0 if line[4]=='M' else 1\n",
    "        dic_audios_inf[line[0]]['AGE'] = int(line[5])\n",
    "fp.close()\n",
    "metadata_df = pd.DataFrame(dic_audios_inf).transpose()\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extraeremos las características de VGGish embeddings para los read-text y para cada una de las vocales.**\n",
    "\n",
    "> Audio -->**|Preprocesado|**--> MFCC y espectros para cada segundo -->**|VGGish|**-->Embeddings-->**|Media y desviacion|**--> final embeddings\n",
    "\n",
    "##  Extracción VGGish embeddings read-text\n",
    "\n",
    "**Todos los audios de Read Text satisfacen ser mayores de 0.95 segundos, por lo que la librería procesará todos sin descartar ninguno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from extractor_ccas_vggish import Extractor_Caracteristicas_Vggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "extractor = Extractor_Caracteristicas_Vggish(rutaCcas,dic_audios_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comienzo extracción HC, quedan: 100 audios.\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Comienzo extracción PD, quedan: 50 audios.\n"
     ]
    }
   ],
   "source": [
    "vggish_embed_rt_ccas = extractor.extraccion_embeddings_directorio('PC-GITA/read-text/',['SEX','AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 259)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_embed_rt_ccas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278153</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.107849</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.00377</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>0.119562</td>\n",
       "      <td>0.158425</td>\n",
       "      <td>0.081016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325714</td>\n",
       "      <td>0.034539</td>\n",
       "      <td>0.436125</td>\n",
       "      <td>0.034923</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318470</td>\n",
       "      <td>0.276926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264087</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>0.381020</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.012588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260098</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.292940</td>\n",
       "      <td>0.291935</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401916</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.207072</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151806</td>\n",
       "      <td>0.220594</td>\n",
       "      <td>0.207069</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.044313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015651</td>\n",
       "      <td>0.053887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140579</td>\n",
       "      <td>0.245352</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4        5         6    \\\n",
       "0  0.278153  0.012632  0.107849  0.003633  0.002978  0.00377  0.019045   \n",
       "1  0.325714  0.034539  0.436125  0.034923  0.010663  0.00000  0.001808   \n",
       "2  0.264087  0.020774  0.381020  0.005155  0.008006  0.00000  0.012588   \n",
       "3  0.401916  0.011046  0.207072  0.016177  0.000000  0.00000  0.000000   \n",
       "4  0.850589  0.000000  0.234680  0.000000  0.024994  0.00000  0.000000   \n",
       "\n",
       "        7         8         9   ...        249       250       251       252  \\\n",
       "0  0.000866  0.004500  0.037274 ...   0.434527  0.000000  0.118272  0.119562   \n",
       "1  0.000000  0.030295  0.013750 ...   0.059658  0.000000  0.318470  0.276926   \n",
       "2  0.000000  0.001721  0.003728 ...   0.260098  0.015644  0.292940  0.291935   \n",
       "3  0.001114  0.000000  0.029870 ...   0.098720  0.000000  0.151806  0.220594   \n",
       "4  0.000000  0.015651  0.053887 ...   0.146179  0.000000  0.140579  0.245352   \n",
       "\n",
       "        253       254       255  256   257  258  \n",
       "0  0.158425  0.081016  0.000000  0.0  64.0  1.0  \n",
       "1  0.000000  0.013921  0.058811  1.0  72.0  1.0  \n",
       "2  0.022067  0.026897  0.034241  1.0  75.0  1.0  \n",
       "3  0.207069  0.004790  0.044313  0.0  65.0  1.0  \n",
       "4  0.010431  0.000000  0.000000  1.0  66.0  1.0  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vggish_embed_rt_ccas).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch = Bunch(data = vggish_embed_rt_ccas[:,:-1], \n",
    "                  target = vggish_embed_rt_ccas[:,-1], \n",
    "                  UPDRS = np.array(metadata_df['UPDRS']), \n",
    "                  UPDRS_SPEECH = np.array(metadata_df['UPDRS_SPEECH']), \n",
    "                  HY = np.array(metadata_df['HY']) )\n",
    "    \n",
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_rt_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extracción VGGish embeddings VOCALES\n",
    "\n",
    "**NO todos los audios de Read Text satisfacen ser mayores de 0.95 segundos, por lo que la librería descartará audios automáticamente**.\n",
    "\n",
    "**Debemos procesar audio a audio para poder insertar correctamente las labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_keras\n",
    "import os\n",
    "from sklearn.utils import Bunch\n",
    "    \n",
    "class Ex_Ccas_Vggish:\n",
    "    \n",
    "    ''' \n",
    "    Clase encargada de la extracción de características de los audios con la herramienta VGGish \n",
    "\n",
    "    author: Adrián Arnaiz\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    rutaCcas: str\n",
    "        ruta donde guardar los archivos de características\n",
    "    dic_inf_audios: dict\n",
    "        diccionario donde se guardan atributos extra para cada audio.\n",
    "        Clave: nombre del audio. Valor: Diccionario con claves el nombre de atributo y valor el valor.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, rutaCarac, dic_inf_audios=None):\n",
    "\n",
    "        '''\n",
    "        Paramteros\n",
    "        ----------\n",
    "        rutaCarac: str\n",
    "            ruta donde guardar los archivos de características\n",
    "        dic_inf_audios: dict\n",
    "            diccionario donde se guardan atributos extra para cada audio.\n",
    "            Clave: nombre del audio. Valor: Diccionario con claves el nombre de atributo y valor el valor.\n",
    "        '''\n",
    "\n",
    "        self.rutaCcas = '../'+rutaCarac #i.e.: CaracteristicasExtraidas/Vggish/embeddings||espectros/\n",
    "        \n",
    "        try: \n",
    "            os.mkdir(self.rutaCcas)\n",
    "        except FileExistsError:\n",
    "            print('Directorio de características ya existente, no se crea nuevo.')\n",
    "        \n",
    "        self.dic_inf_audios = dic_inf_audios\n",
    "        \n",
    "        #Definimos VGGish\n",
    "        self.model = vggish_keras.get_vggish_keras()\n",
    "        #Cargamos el checkpoint\n",
    "        checkpoint_path = 'vggish_weights.ckpt'\n",
    "        self.model.load_weights(checkpoint_path)\n",
    "        \n",
    "        \n",
    "    def add_target(self, ccas, parkinson):\n",
    "        ''' \n",
    "        Añade la colmuna target. PD: 1, HC: 0. \n",
    "        \n",
    "        Parametros\n",
    "        ----------\n",
    "        ccas : numpy.array 2 dimensiones\n",
    "            matriz de ccas de audios a la que añadir la última columna\n",
    "        parkinson: bool\n",
    "            booleano indicando si se quiere añadir columna parkinson o no\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            matriz con la clase añadida.\n",
    "        '''\n",
    "        return np.hstack((ccas,np.ones((ccas.shape[0],1)))) if parkinson else np.hstack((ccas,np.zeros((ccas.shape[0],1))))\n",
    "    \n",
    "    def extraccion_embeddings_directorio(self, aud, extra_atribs=None, embeddings = True):\n",
    "        '''\n",
    "        Devuelve en numpy las medidas de los todos audios de un directorio que saca el VGGish y se guardan en el archivo ccas.npy.\n",
    "        Recorre para un tipo de audio primero los sanos y los etiqueta y posteriormente hace lo mismo con los PD.\n",
    "        Finalmente los concatena.\n",
    "\n",
    "\n",
    "        Parametros\n",
    "        ----------\n",
    "        aud: str\n",
    "            ruta del directorio de audios a analizar respecto a src/. i.e: 'PC-GITA/read-text/'. Debe subcontener hc y pd.\n",
    "        extra_atribs: list(string)\n",
    "            atributos extra a añadir a las caracteriticas. i.e. edad o sexo. lista con los nombres \n",
    "            de los atributos a añadir del self.dic_inf_audios\n",
    "        embeddings:boolean\n",
    "            Si es true sacamos los embeddings, si false sacamos los espectros\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            matriz de instancias con sus ccas extraidas y atributos añadidos si fuese necesario.\n",
    "            Serán embeddings o espectros en función de el parámetro boolean.\n",
    "        '''\n",
    "        rutaAudios = '../'+aud \n",
    "\n",
    "        \n",
    "        ######\n",
    "        ##HC##\n",
    "        ######\n",
    "        rutaAudiosTipo = rutaAudios+'hc/'\n",
    "        audios = os.listdir(rutaAudiosTipo)\n",
    "        print('Comienzo extracción HC, quedan:', len(audios)*2,'audios.')        \n",
    "        \n",
    "        ccas_hc=[]\n",
    "\n",
    "        for audio in audios:\n",
    "            embedd = self.extraccion_embeddings_audio(rutaAudiosTipo+audio, embeddings)\n",
    "            \n",
    "            #Si es nan tiene shape 2, ponemos shape igual a los demás para evitar fallos\n",
    "            if(np.isnan(embedd).any()):\n",
    "                embedd = np.empty((256,))\n",
    "                embedd[:] = np.NaN\n",
    "            \n",
    "            #Cogemos los metadatos y añadimos edad y sexo como atributo\n",
    "            metadata = self.dic_inf_audios[audio[:-6]]\n",
    "            embedd = np.append(embedd, \n",
    "                               [metadata['SEX'],\n",
    "                                metadata['AGE'],\n",
    "                                0,\n",
    "                                metadata['UPDRS'],\n",
    "                                metadata['UPDRS_SPEECH'],\n",
    "                                metadata['HY']\n",
    "                               ])\n",
    "            \n",
    "            assert embedd.shape[0]==256+2+4\n",
    "            \n",
    "            #Añadimos las ccas a la matriz de ccas\n",
    "            ccas_hc.append(embedd)\n",
    "            \n",
    "        ccas_hc=np.array(ccas_hc)\n",
    "\n",
    "        #Borramos los audios de menos de un segundo, cuya salida de vggish es np.array([nan,nan],)\n",
    "        ccas_hc = np.array([instancia for instancia in ccas_hc if not np.isnan(instancia).any()])\n",
    "\n",
    "    \n",
    "        ######\n",
    "        ##PD##\n",
    "        ######\n",
    "        print('Comienzo extracción PD, quedan:', len(audios),'audios.')\n",
    "\n",
    "        rutaAudiosTipo = rutaAudios+'pd/'\n",
    "        audios = os.listdir(rutaAudiosTipo)\n",
    "        \n",
    "        ccas_pd=[]\n",
    "\n",
    "        for audio in audios:\n",
    "            embedd = self.extraccion_embeddings_audio(rutaAudiosTipo+audio, embeddings)\n",
    "            \n",
    "            #Si es nan tiene shape 2, ponemos shape igual a los demás para evitar fallos\n",
    "            if(np.isnan(embedd).any()):\n",
    "                embedd = np.empty((256,))\n",
    "                embedd[:] = np.NaN\n",
    "            \n",
    "            #Cogemos los metadatos y añadimos edad y sexo como atributo\n",
    "            metadata = self.dic_inf_audios[audio[:-6]]\n",
    "            embedd = np.append(embedd, \n",
    "                               [metadata['SEX'],\n",
    "                                metadata['AGE'],\n",
    "                                1,\n",
    "                                metadata['UPDRS'],\n",
    "                                metadata['UPDRS_SPEECH'],\n",
    "                                metadata['HY']\n",
    "                               ])\n",
    "            \n",
    "            \n",
    "            assert embedd.shape[0]==256+2+4\n",
    "            \n",
    "            #Añadimos las ccas a la matriz de ccas\n",
    "            ccas_pd.append(embedd)\n",
    "            \n",
    "        ccas_pd=np.array(ccas_pd)\n",
    "\n",
    "        #Limpiamos\n",
    "        ccas_pd = np.array([instancia for instancia in ccas_pd if not np.isnan(instancia).any()])\n",
    "\n",
    "        #Devolvemos todo el conjunto entero junto\n",
    "        return np.concatenate((ccas_hc, ccas_pd))\n",
    "\n",
    "  \n",
    "    def extraccion_embeddings_audio(self, rutaAudio, embeddings):\n",
    "        '''Extrae de un único audio, la media y la desviación de los 128 embeddings, para devolver \n",
    "        un vector de 256 ccas por audio o los 128 espectros en caso de que embeddings sea falso.\n",
    "        \n",
    "        Parametros\n",
    "        ----------\n",
    "        rutaAudio:str\n",
    "            ruta del audio en concreto\n",
    "        embeddings:boolean\n",
    "            Si es true sacamos los embeddings, si false sacamos los espectros\n",
    "        Return\n",
    "        ------\n",
    "        final_ccas: numpy.array\n",
    "            array de características del audio. Embeddings o espectros.\n",
    "        '''\n",
    "        #1. Sacamos las ccas MFCC y espectrales\n",
    "        input_batch  = vggish_input.wavfile_to_examples(rutaAudio)\n",
    "\n",
    "        #2. producimos los embbeding cn el modelo o los espectros segun se indique\n",
    "        if embeddings:\n",
    "            ccas = self.model.predict(input_batch[:,:,:,None])\n",
    "        else:\n",
    "            # \"Rompemos\" los grupos de 0.96s\n",
    "            ccas = input_batch.reshape(-1, input_batch.shape[-1])\n",
    "        \n",
    "        \n",
    "        #3. Hacemos media y deviación de los embbedings\n",
    "        media = np.mean(ccas,axis=0)\n",
    "        desvs = np.std(ccas,axis=0)\n",
    "        final_ccas = np.append(media,desvs)\n",
    "        \n",
    "        return final_ccas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letra A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Comienzo extracción HC, quedan: 300 audios.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Users\\Usuario\\.conda\\envs\\pk\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comienzo extracción PD, quedan: 150 audios.\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "\n",
    "extractor = Ex_Ccas_Vggish(rutaCcas, dic_audios_inf)\n",
    "\n",
    "dtst = extractor.extraccion_embeddings_directorio('PC-GITA/vowels/A/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_a = Bunch(data = dtst[:,:-4],\n",
    "               target = dtst[:,-4], \n",
    "               UPDRS = dtst[:,-3],\n",
    "               UPDRS_SPEECH = dtst[:,-2],\n",
    "               HY = dtst[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_v_A_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch_a, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Comienzo extracción HC, quedan: 300 audios.\n",
      "Comienzo extracción PD, quedan: 150 audios.\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "\n",
    "extractor = Ex_Ccas_Vggish(rutaCcas, dic_audios_inf)\n",
    "\n",
    "dtst = extractor.extraccion_embeddings_directorio('PC-GITA/vowels/E/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_e = Bunch(data = dtst[:,:-4],\n",
    "               target = dtst[:,-4], \n",
    "               UPDRS = dtst[:,-3],\n",
    "               UPDRS_SPEECH = dtst[:,-2],\n",
    "               HY = dtst[:,-1])\n",
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_v_E_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch_e, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Comienzo extracción HC, quedan: 300 audios.\n",
      "Comienzo extracción PD, quedan: 150 audios.\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "\n",
    "extractor = Ex_Ccas_Vggish(rutaCcas, dic_audios_inf)\n",
    "\n",
    "dtst = extractor.extraccion_embeddings_directorio('PC-GITA/vowels/I/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_i = Bunch(data = dtst[:,:-4],\n",
    "               target = dtst[:,-4], \n",
    "               UPDRS = dtst[:,-3],\n",
    "               UPDRS_SPEECH = dtst[:,-2],\n",
    "               HY = dtst[:,-1])\n",
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_v_I_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch_i, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Comienzo extracción HC, quedan: 300 audios.\n",
      "Comienzo extracción PD, quedan: 150 audios.\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "\n",
    "extractor = Ex_Ccas_Vggish(rutaCcas, dic_audios_inf)\n",
    "\n",
    "dtst = extractor.extraccion_embeddings_directorio('PC-GITA/vowels/O/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_o = Bunch(data = dtst[:,:-4],\n",
    "               target = dtst[:,-4], \n",
    "               UPDRS = dtst[:,-3],\n",
    "               UPDRS_SPEECH = dtst[:,-2],\n",
    "               HY = dtst[:,-1])\n",
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_v_O_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch_o, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Comienzo extracción HC, quedan: 300 audios.\n",
      "Comienzo extracción PD, quedan: 150 audios.\n"
     ]
    }
   ],
   "source": [
    "rutaCcas = 'CaracteristicasExtraidas/Regression/embbedings/'\n",
    "\n",
    "extractor = Ex_Ccas_Vggish(rutaCcas, dic_audios_inf)\n",
    "\n",
    "dtst = extractor.extraccion_embeddings_directorio('PC-GITA/vowels/U/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch_u = Bunch(data = dtst[:,:-4],\n",
    "               target = dtst[:,-4], \n",
    "               UPDRS = dtst[:,-3],\n",
    "               UPDRS_SPEECH = dtst[:,-2],\n",
    "               HY = dtst[:,-1])\n",
    "pickle_out = open('../CaracteristicasExtraidas/Regression/embbedings/vggish_embed_v_U_ccas.bunch',\"wb\")\n",
    "pk.dump(bunch_u, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.6.8PK",
   "language": "python",
   "name": "pk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
