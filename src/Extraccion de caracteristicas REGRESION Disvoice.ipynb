{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creamos diccionario de metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>HY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>UPDRS</th>\n",
       "      <th>UPDRS_SPEECH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0001</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0002</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0003</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0005</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0006</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0007</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0008</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0009</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0010</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0011</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE  HY  SEX  UPDRS  UPDRS_SPEECH\n",
       "AVPEPUDEA0001   64   2    0     28             1\n",
       "AVPEPUDEA0002   72   1    1     19             0\n",
       "AVPEPUDEA0003   75   3    1     52             2\n",
       "AVPEPUDEA0005   65   2    0     32             1\n",
       "AVPEPUDEA0006   66   2    1     28             1\n",
       "AVPEPUDEA0007   55   2    1     30             1\n",
       "AVPEPUDEA0008   60   2    1     29             1\n",
       "AVPEPUDEA0009   57   3    1     41             1\n",
       "AVPEPUDEA0010   51   3    1     38             2\n",
       "AVPEPUDEA0011   55   3    1     43             2"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos el diccionario con la estructura indicada\n",
    "filepath = 'PC-GITA/PCGITA_metadata.csv'\n",
    "dic_audios_inf = dict()\n",
    "with open(filepath) as fp:\n",
    "    cnt = 0\n",
    "    for line in fp:\n",
    "        line = line.split(';')[:8]\n",
    "        if not line[0].startswith('AVP'):\n",
    "            line[0]=line[0][3:]\n",
    "        dic_audios_inf[line[0]]=dict()\n",
    "        dic_audios_inf[line[0]]['UPDRS'] = 0 if line[1]=='' else int(line[1])\n",
    "        dic_audios_inf[line[0]]['UPDRS_SPEECH'] = 0 if line[2]=='' else int(line[2])\n",
    "        dic_audios_inf[line[0]]['HY'] = 0 if line[3]=='' else int(line[3][0])\n",
    "        dic_audios_inf[line[0]]['SEX'] = 0 if line[4]=='M' else 1\n",
    "        dic_audios_inf[line[0]]['AGE'] = int(line[5])\n",
    "fp.close()\n",
    "metadata_df = pd.DataFrame(dic_audios_inf).transpose()\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DISVOICE\n",
    "## 2.1. Adición a características ya extraídas\n",
    "\n",
    "**Anteriormente hemos extraido características y limpiado**.\n",
    "\n",
    "**Debemos identificar en qué conjuntos de datos hemos borrado alguna instancia (limpieza de NaN) para volver a sacar esos datos.**\n",
    "\n",
    "**En los conjuntos que no hayamos borrado ninguna instancia, podremos ahorrarnos la reextracción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cargaDatosEdSx as loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_extract = []\n",
    "completos = []\n",
    "for ld in dir(loader):\n",
    "    if ld.startswith('load'): \n",
    "        forma = eval(\"loader.\"+str(ld)+'()[\\'data\\']').shape\n",
    "        if forma[0]==100 or forma[0]==300:\n",
    "            completos.append(ld)\n",
    "        else:\n",
    "            re_extract.append(ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_art_rt',\n",
       " 'load_art_w_atleta',\n",
       " 'load_art_w_braso',\n",
       " 'load_art_w_campana',\n",
       " 'load_art_w_gato',\n",
       " 'load_art_w_petaka',\n",
       " 'load_fon_rt',\n",
       " 'load_fon_v_A',\n",
       " 'load_fon_v_E',\n",
       " 'load_fon_v_I',\n",
       " 'load_fon_v_O',\n",
       " 'load_fon_v_U',\n",
       " 'load_fon_w_campana',\n",
       " 'load_prs_rt']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_fon_w_atleta',\n",
       " 'load_fon_w_braso',\n",
       " 'load_fon_w_gato',\n",
       " 'load_fon_w_petaka']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in completos:\n",
    "    bunch = eval(\"loader.\"+str(c)+'()')\n",
    "    forma = bunch['data'].shape\n",
    "    if forma[0]==100:\n",
    "        bunch['UPDRS'] = np.array(metadata_df['UPDRS'])\n",
    "        bunch['UPDRS_SPEECH'] = np.array(metadata_df['UPDRS_SPEECH'])\n",
    "        bunch['HY'] = np.array(metadata_df['HY'])\n",
    "    elif forma[0]==300:\n",
    "        bunch['UPDRS'] = np.array(np.repeat(metadata_df['UPDRS'],3))\n",
    "        bunch['UPDRS_SPEECH'] = np.array(np.repeat(metadata_df['UPDRS_SPEECH'],3))\n",
    "        bunch['HY'] = np.array(np.repeat(metadata_df['HY'],3))\n",
    "    else:\n",
    "        print('FALLO')\n",
    "    pickle_out = open('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+c[5:]+'_ccas.bunch',\"wb\")\n",
    "    pk.dump(bunch, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Extraccion ccas Disvoice para 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_fon_w_atleta',\n",
       " 'load_fon_w_braso',\n",
       " 'load_fon_w_gato',\n",
       " 'load_fon_w_petaka']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extractorCcas import ExtractorCaracteristicas\n",
    "re_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonation_word_extraction(palabras):\n",
    "    '''\n",
    "    Llamamos a la función de extracción de características con las rutas necesarias\n",
    "    '''\n",
    "    ccas_palabras = dict()\n",
    "    for p in palabras:\n",
    "        extractor = ExtractorCaracteristicas('PC-GITA/words/'+p+'/','CaracteristicasExtraidas/Regression/Orozco/', dic_audios_inf)\n",
    "        ccas_palabras[p]= extractor.extraccion_ccas_directorio('phonation', 'fon_w_'+p+'_hc.txt' , 'fon_w_'+p+'_pd.txt', ['AGE','SEX'] )\n",
    "        print('Palabras analizadas: ',ccas_palabras.keys())\n",
    "    return ccas_palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato', 'petaka'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato', 'petaka', 'braso'])\n"
     ]
    }
   ],
   "source": [
    "words=['atleta','gato','petaka','braso']\n",
    "fon_words_ccas = phonation_word_extraction(words)\n",
    "for k in fon_words_ccas:\n",
    "    np.save('CaracteristicasExtraidas/Regression/Orozco/fon_w_'+k+'_ccas',fon_words_ccas[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiamos los datos y Creamos objeto bunch con datos, label binaria, y labels numéricas (UPDRS, UPDRS speech e HY), teniendo en cuenta los índices de datos que hemos borado a la hora de obtener los labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "\n",
      "--------------\n",
      " fon_w_atleta_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {57}\n",
      "\tNumero de audios con NaN:  1\n",
      "\t% de Nan en audios PD:  1.0\n",
      "\n",
      "--------------\n",
      " fon_w_braso_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {28, 69, 15}\n",
      "\tNumero de audios con NaN:  3\n",
      "\t% de Nan en audios PD:  0.3333333333333333\n",
      "\n",
      "--------------\n",
      " fon_w_gato_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {15, 18, 19, 27, 28, 34, 36, 37, 42, 45, 57, 60, 61, 67, 69, 70, 73, 80, 81, 83, 88, 91, 96, 98}\n",
      "\tNumero de audios con NaN:  24\n",
      "\t% de Nan en audios PD:  0.5833333333333334\n",
      "\n",
      "--------------\n",
      " fon_w_petaka_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {57, 45, 77, 13}\n",
      "\tNumero de audios con NaN:  4\n",
      "\t% de Nan en audios PD:  0.5\n"
     ]
    }
   ],
   "source": [
    "ex = ExtractorCaracteristicas('daigual','CaracteristicasExtraidas/Regression/Orozco/')\n",
    "dc = ex.identificadorNan('CaracteristicasExtraidas/Regression/Orozco/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.tratamiento_nan('CaracteristicasExtraidas/Regression/Orozco/', dc)\n",
    "ex.identificadorNan('CaracteristicasExtraidas/Regression/Orozco/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fon_w_atleta_ccas.npy\n",
      "(99, 31)\n",
      "(99,)\n",
      "(99,)\n",
      "--------------\n",
      "fon_w_braso_ccas.npy\n",
      "(97, 31)\n",
      "(97,)\n",
      "(97,)\n",
      "--------------\n",
      "fon_w_gato_ccas.npy\n",
      "(76, 31)\n",
      "(76,)\n",
      "(76,)\n",
      "--------------\n",
      "fon_w_petaka_ccas.npy\n",
      "(96, 31)\n",
      "(96,)\n",
      "(96,)\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for dtst in dc:\n",
    "    data = np.load('CaracteristicasExtraidas/Regression/Orozco/'+dtst)\n",
    "    \n",
    "    attributes = data[:,:-1]\n",
    "    label_binary = data[:,-1]\n",
    "    \n",
    "    labels_limpias = metadata_df.drop(metadata_df.index[ list(dc[dtst][0])])\n",
    "    \n",
    "    updrs = np.array(labels_limpias['UPDRS'])\n",
    "    updrs_speech = np.array(labels_limpias['UPDRS_SPEECH'])\n",
    "    hy =  np.array(labels_limpias['HY'])\n",
    "    \n",
    "    bunch = Bunch(data = attributes, \n",
    "                  target = label_binary, \n",
    "                  UPDRS = updrs, \n",
    "                  UPDRS_SPEECH = updrs_speech, \n",
    "                  HY = hy )\n",
    "    \n",
    "    pickle_out = open('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+dtst[:-4]+'.bunch',\"wb\")\n",
    "    pk.dump(bunch, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    print(dtst)\n",
    "    print(attributes.shape)\n",
    "    print(label_binary.shape)\n",
    "    print(updrs.shape)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'CaracteristicasExtraidas\\\\Regression\\\\Orozco\\\\fon_w_petaka_ccas.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-f2054f5357b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CaracteristicasExtraidas\\Regression\\Orozco\\\\fon_w_petaka_ccas.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'npy'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CaracteristicasExtraidas\\Regression\\Orozco\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'CaracteristicasExtraidas\\\\Regression\\\\Orozco\\\\fon_w_petaka_ccas.npy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for f in os.listdir('CaracteristicasExtraidas\\Regression\\Orozco\\\\'):\n",
    "    if f.endswith('npy') or f.endswith('txt'):\n",
    "        os.remove('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "(96, 31)\n",
      "(96,)\n",
      "(96,)\n",
      "(96,)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "bn = pk.load(open(r'CaracteristicasExtraidas\\Regression\\Orozco\\fon_w_petaka_ccas.bunch','rb'))\n",
    "print(type(bn))\n",
    "for k in bn.keys():\n",
    "    print(bn[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cargaDatosVggishEmbeddings as loaderVggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_vggish_embed_rt (100, 258)\n",
      "load_vggish_embed_v_A (282, 256)\n",
      "load_vggish_embed_v_E (284, 256)\n",
      "load_vggish_embed_v_I (281, 256)\n",
      "load_vggish_embed_v_O (262, 256)\n",
      "load_vggish_embed_v_U (254, 256)\n"
     ]
    }
   ],
   "source": [
    "vggish_re_extract = []\n",
    "vggish_completos = []\n",
    "for ld in dir(loaderVggish):\n",
    "    if ld.startswith('load'): \n",
    "        forma = eval(\"loaderVggish.\"+str(ld)+'()[\\'data\\']').shape\n",
    "        print(ld, forma)\n",
    "        if forma[0]==100 or forma[0]==300:\n",
    "            vggish_completos.append(ld)\n",
    "        else:\n",
    "            vggish_re_extract.append(ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_vggish_embed_rt']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_vggish_embed_v_A',\n",
       " 'load_vggish_embed_v_E',\n",
       " 'load_vggish_embed_v_I',\n",
       " 'load_vggish_embed_v_O',\n",
       " 'load_vggish_embed_v_U']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggish_re_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
