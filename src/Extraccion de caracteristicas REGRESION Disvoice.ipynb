{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creamos diccionario de metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>HY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>UPDRS</th>\n",
       "      <th>UPDRS_SPEECH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0001</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0002</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0003</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0005</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0006</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0007</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0008</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0009</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0010</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVPEPUDEA0011</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE  HY  SEX  UPDRS  UPDRS_SPEECH\n",
       "AVPEPUDEA0001   64   2    0     28             1\n",
       "AVPEPUDEA0002   72   1    1     19             0\n",
       "AVPEPUDEA0003   75   3    1     52             2\n",
       "AVPEPUDEA0005   65   2    0     32             1\n",
       "AVPEPUDEA0006   66   2    1     28             1\n",
       "AVPEPUDEA0007   55   2    1     30             1\n",
       "AVPEPUDEA0008   60   2    1     29             1\n",
       "AVPEPUDEA0009   57   3    1     41             1\n",
       "AVPEPUDEA0010   51   3    1     38             2\n",
       "AVPEPUDEA0011   55   3    1     43             2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos el diccionario con la estructura indicada\n",
    "filepath = 'PC-GITA/PCGITA_metadata.csv'\n",
    "dic_audios_inf = dict()\n",
    "with open(filepath) as fp:\n",
    "    cnt = 0\n",
    "    for line in fp:\n",
    "        line = line.split(';')[:8]\n",
    "        if not line[0].startswith('AVP'):\n",
    "            line[0]=line[0][3:]\n",
    "        dic_audios_inf[line[0]]=dict()\n",
    "        dic_audios_inf[line[0]]['UPDRS'] = 0 if line[1]=='' else int(line[1])\n",
    "        dic_audios_inf[line[0]]['UPDRS_SPEECH'] = 0 if line[2]=='' else int(line[2])\n",
    "        dic_audios_inf[line[0]]['HY'] = 0 if line[3]=='' else int(line[3][0])\n",
    "        dic_audios_inf[line[0]]['SEX'] = 0 if line[4]=='M' else 1\n",
    "        dic_audios_inf[line[0]]['AGE'] = int(line[5])\n",
    "fp.close()\n",
    "metadata_df = pd.DataFrame(dic_audios_inf).transpose()\n",
    "metadata_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DISVOICE\n",
    "## 2.1. Adición a características ya extraídas\n",
    "\n",
    "**Anteriormente hemos extraido características y limpiado**.\n",
    "\n",
    "**Debemos identificar en qué conjuntos de datos hemos borrado alguna instancia (limpieza de NaN) para volver a sacar esos datos.**\n",
    "\n",
    "**En los conjuntos que no hayamos borrado ninguna instancia, podremos ahorrarnos la reextracción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cargaDatosEdSx as loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_extract = []\n",
    "completos = []\n",
    "for ld in dir(loader):\n",
    "    if ld.startswith('load'): \n",
    "        forma = eval(\"loader.\"+str(ld)+'()[\\'data\\']').shape\n",
    "        if forma[0]==100 or forma[0]==300:\n",
    "            completos.append(ld)\n",
    "        else:\n",
    "            re_extract.append(ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_art_rt',\n",
       " 'load_art_w_atleta',\n",
       " 'load_art_w_braso',\n",
       " 'load_art_w_campana',\n",
       " 'load_art_w_gato',\n",
       " 'load_art_w_petaka',\n",
       " 'load_fon_rt',\n",
       " 'load_fon_v_A',\n",
       " 'load_fon_v_E',\n",
       " 'load_fon_v_I',\n",
       " 'load_fon_v_O',\n",
       " 'load_fon_v_U',\n",
       " 'load_fon_w_campana',\n",
       " 'load_prs_rt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_fon_w_atleta',\n",
       " 'load_fon_w_braso',\n",
       " 'load_fon_w_gato',\n",
       " 'load_fon_w_petaka']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las ccas están sacadas primero para sanos y luego para PD, debemos invertir el orden del array de labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 19, 52, 32, 28, 30, 29, 41, 38, 43,  6, 61, 28, 44, 50, 30, 42,\n",
       "       20, 14, 93, 53, 21, 13, 19, 75, 40, 30, 19, 23, 40,  9, 67, 15, 54,\n",
       "       51, 71, 40, 40, 53, 28, 38, 57, 23, 33, 30, 53, 45, 65, 21, 29,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(metadata_df['UPDRS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_updrs = np.array(metadata_df['UPDRS'][:])\n",
    "\n",
    "global_updrs_speech = np.array(metadata_df['UPDRS_SPEECH'][:])\n",
    "\n",
    "global_hy = np.array(metadata_df['HY'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(global_hy,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in completos:\n",
    "    bunch = eval(\"loader.\"+str(c)+'()')\n",
    "    forma = bunch['data'].shape\n",
    "    if forma[0]==100:\n",
    "        bunch['UPDRS'] = global_updrs\n",
    "        bunch['UPDRS_SPEECH'] = global_updrs_speech\n",
    "        bunch['HY'] = global_hy\n",
    "    elif forma[0]==300:\n",
    "        bunch['UPDRS'] = np.array(np.repeat(global_updrs,3))\n",
    "        bunch['UPDRS_SPEECH'] = np.array(np.repeat(global_updrs_speech,3))\n",
    "        bunch['HY'] = np.array(np.repeat(global_hy,3))\n",
    "    else:\n",
    "        print('FALLO')\n",
    "    pickle_out = open('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+c[5:]+'_ccas.bunch',\"wb\")\n",
    "    pk.dump(bunch, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Extraccion ccas Disvoice para 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_fon_w_atleta',\n",
       " 'load_fon_w_braso',\n",
       " 'load_fon_w_gato',\n",
       " 'load_fon_w_petaka']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extractorCcas import ExtractorCaracteristicas\n",
    "re_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonation_word_extraction(palabras):\n",
    "    '''\n",
    "    Llamamos a la función de extracción de características con las rutas necesarias\n",
    "    '''\n",
    "    ccas_palabras = dict()\n",
    "    for p in palabras:\n",
    "        extractor = ExtractorCaracteristicas('PC-GITA/words/'+p+'/','CaracteristicasExtraidas/Regression/Orozco/', dic_audios_inf)\n",
    "        ccas_palabras[p]= extractor.extraccion_ccas_directorio('phonation', 'fon_w_'+p+'_hc.txt' , 'fon_w_'+p+'_pd.txt', ['AGE','SEX'] )\n",
    "        print('Palabras analizadas: ',ccas_palabras.keys())\n",
    "    return ccas_palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato', 'petaka'])\n",
      "Directorio de características ya existente, no se crea nuevo.\n",
      "Palabras analizadas:  dict_keys(['atleta', 'gato', 'petaka', 'braso'])\n"
     ]
    }
   ],
   "source": [
    "words=['atleta','gato','petaka','braso']\n",
    "fon_words_ccas = phonation_word_extraction(words)\n",
    "for k in fon_words_ccas:\n",
    "    np.save('CaracteristicasExtraidas/Regression/Orozco/fon_w_'+k+'_ccas',fon_words_ccas[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpiamos los datos y Creamos objeto bunch con datos, label binaria, y labels numéricas (UPDRS, UPDRS speech e HY), teniendo en cuenta los índices de datos que hemos borado a la hora de obtener los labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de características ya existente, no se crea nuevo.\n",
      "\n",
      "--------------\n",
      " fon_w_atleta_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {7}\n",
      "\tNumero de audios con NaN:  1\n",
      "\t% de Nan en audios PD:  0.0\n",
      "\n",
      "--------------\n",
      " fon_w_braso_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {65, 19, 78}\n",
      "\tNumero de audios con NaN:  3\n",
      "\t% de Nan en audios PD:  0.6666666666666666\n",
      "\n",
      "--------------\n",
      " fon_w_gato_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {7, 10, 11, 17, 19, 20, 23, 30, 31, 33, 38, 41, 46, 48, 65, 68, 69, 77, 78, 84, 86, 87, 92, 95}\n",
      "\tNumero de audios con NaN:  24\n",
      "\t% de Nan en audios PD:  0.4166666666666667\n",
      "\n",
      "--------------\n",
      " fon_w_petaka_ccas.npy\n",
      "\t(Audios, atrib):  (100, 32)\n",
      "\tAudios con NaN:  {27, 63, 95, 7}\n",
      "\tNumero de audios con NaN:  4\n",
      "\t% de Nan en audios PD:  0.5\n"
     ]
    }
   ],
   "source": [
    "ex = ExtractorCaracteristicas('daigual','CaracteristicasExtraidas/Regression/Orozco/')\n",
    "dc = ex.identificadorNan('CaracteristicasExtraidas/Regression/Orozco/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.tratamiento_nan('CaracteristicasExtraidas/Regression/Orozco/', dc)\n",
    "ex.identificadorNan('CaracteristicasExtraidas/Regression/Orozco/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fon_w_atleta_ccas.npy\n",
      "(99, 31)\n",
      "(99,)\n",
      "(99,)\n",
      "--------------\n",
      "fon_w_braso_ccas.npy\n",
      "(97, 31)\n",
      "(97,)\n",
      "(97,)\n",
      "--------------\n",
      "fon_w_gato_ccas.npy\n",
      "(76, 31)\n",
      "(76,)\n",
      "(76,)\n",
      "--------------\n",
      "fon_w_petaka_ccas.npy\n",
      "(96, 31)\n",
      "(96,)\n",
      "(96,)\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for dtst in dc:\n",
    "    data = np.load('CaracteristicasExtraidas/Regression/Orozco/'+dtst)\n",
    "    \n",
    "    attributes = data[:,:-1]\n",
    "    label_binary = data[:,-1]\n",
    "    \n",
    "    labels_limpias = metadata_df.drop(metadata_df.index[ list(dc[dtst][0])])\n",
    "    \n",
    "    updrs = np.array(labels_limpias['UPDRS'])\n",
    "    updrs_speech = np.array(labels_limpias['UPDRS_SPEECH'])\n",
    "    hy =  np.array(labels_limpias['HY'])\n",
    "    \n",
    "    bunch = Bunch(data = attributes, \n",
    "                  target = label_binary, \n",
    "                  UPDRS = updrs, \n",
    "                  UPDRS_SPEECH = updrs_speech, \n",
    "                  HY = hy )\n",
    "    \n",
    "    pickle_out = open('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+dtst[:-4]+'.bunch',\"wb\")\n",
    "    pk.dump(bunch, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    print(dtst)\n",
    "    print(attributes.shape)\n",
    "    print(label_binary.shape)\n",
    "    print(updrs.shape)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for f in os.listdir('CaracteristicasExtraidas\\Regression\\Orozco\\\\'):\n",
    "    if f.endswith('npy') or f.endswith('txt'):\n",
    "        os.remove('CaracteristicasExtraidas\\Regression\\Orozco\\\\'+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "(96, 31)\n",
      "(96,)\n",
      "(96,)\n",
      "(96,)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "bn = pk.load(open(r'CaracteristicasExtraidas\\Regression\\Orozco\\fon_w_petaka_ccas.bunch','rb'))\n",
    "print(type(bn))\n",
    "for k in bn.keys():\n",
    "    print(bn[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
